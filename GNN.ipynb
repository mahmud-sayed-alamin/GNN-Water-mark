{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mahmud-sayed-alamin/GNN-Water-mark/blob/main/GNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.datasets import Planetoid\n",
        "from torch_geometric.nn import GCNConv\n",
        "from torch_geometric.data import Data"
      ],
      "metadata": {
        "id": "eMdttRRA3EJL"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = Planetoid(root='/tmp/Cora', name='Cora')\n",
        "data = dataset[0]\n"
      ],
      "metadata": {
        "id": "LIwkaegA3NYC"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "torch.manual_seed(42)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YrGC6I-l3Rky",
        "outputId": "4cf4cd51-8ad8-4628-dfff-626eb6430000"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch._C.Generator at 0x7922d73adfd0>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class GCN(torch.nn.Module):\n",
        "    def __init__(self, in_channels, hidden_channels, out_channels):\n",
        "        super(GCN, self).__init__()\n",
        "        # Define two GCN layers\n",
        "        self.conv1 = GCNConv(in_channels, hidden_channels)\n",
        "        self.conv2 = GCNConv(hidden_channels, out_channels)\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        x = self.conv1(x, edge_index)\n",
        "        x = F.relu(x)\n",
        "        x = F.dropout(x, p=0.05, training=self.training)\n",
        "\n",
        "        x = self.conv2(x, edge_index)\n",
        "        return F.log_softmax(x, dim=1)"
      ],
      "metadata": {
        "id": "AKf-UUpb3Xqj"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GCN(\n",
        "    in_channels=1433,\n",
        "    hidden_channels=32,\n",
        "    out_channels=7\n",
        ")"
      ],
      "metadata": {
        "id": "aqy-Za0w3Y7J"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = model(data.x, data.edge_index)\n",
        "print(out.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zk9L0tk73a35",
        "outputId": "0c14ae33-153a-49a0-bb10-fe70db9409a2"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([2708, 7])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "def compute_loss(output, y, mask):\n",
        "    loss = F.nll_loss(output[mask], y[mask])\n",
        "    return loss\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.01, weight_decay=5e-2)"
      ],
      "metadata": {
        "id": "yw0cL9t83co6"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(data):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "    output = model(data.x, data.edge_index)\n",
        "    loss = compute_loss(output, data.y, data.train_mask)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    return loss.item()"
      ],
      "metadata": {
        "id": "7YGhCNHO3lE4"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def test(data):\n",
        "    model.eval()\n",
        "    output = model(data.x, data.edge_index)\n",
        "    pred = output.argmax(dim=1)\n",
        "    accs = []\n",
        "    for mask in [data.train_mask, data.val_mask, data.test_mask]:\n",
        "        correct = pred[mask].eq(data.y[mask]).sum().item()\n",
        "        acc = correct / mask.sum().item()\n",
        "        accs.append(acc)\n",
        "    return accs"
      ],
      "metadata": {
        "id": "vDr_TyhW3nii"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(data):\n",
        "    model.eval()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        output = model(data.x, data.edge_index)\n",
        "\n",
        "    predictions = output.argmax(dim=1)\n",
        "\n",
        "    accuracies = {}\n",
        "\n",
        "    # **Train Accuracy**\n",
        "    train_correct = predictions[data.train_mask].eq(data.y[data.train_mask]).sum().item()\n",
        "    train_total = data.train_mask.sum().item()\n",
        "    train_accuracy = train_correct / train_total\n",
        "    accuracies['Train'] = train_accuracy\n",
        "\n",
        "    # **Validation Accuracy**\n",
        "    val_correct = predictions[data.val_mask].eq(data.y[data.val_mask]).sum().item()\n",
        "    val_total = data.val_mask.sum().item()\n",
        "    val_accuracy = val_correct / val_total\n",
        "    accuracies['Validation'] = val_accuracy\n",
        "\n",
        "    # **Test Accuracy**\n",
        "    test_correct = predictions[data.test_mask].eq(data.y[data.test_mask]).sum().item()\n",
        "    test_total = data.test_mask.sum().item()\n",
        "    test_accuracy = test_correct / test_total\n",
        "    accuracies['Test'] = test_accuracy\n",
        "\n",
        "    return accuracies\n"
      ],
      "metadata": {
        "id": "TTm_rWzA4ZQ5"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_acc_list = []\n",
        "val_acc_list = []\n",
        "loss_list = []\n",
        "\n",
        "for epoch in range(200):\n",
        "    loss = train(data)\n",
        "    loss_list.append(loss)\n",
        "\n",
        "    accuracies = evaluate(data)\n",
        "    train_acc_list.append(accuracies['Train'])\n",
        "    val_acc_list.append(accuracies['Validation'])\n",
        "\n",
        "    if epoch % 10 == 0:\n",
        "        print(f\"Epoch {epoch:03d}, Loss: {loss:.4f}, \"\n",
        "              f\"Train Acc: {accuracies['Train']:.4f}, \"\n",
        "              f\"Val Acc: {accuracies['Validation']:.4f}, \"\n",
        "              f\"Test Acc: {accuracies['Test']:.4f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jJlR7zH638AY",
        "outputId": "f0b0494c-3487-4545-e49e-309a46e89aed"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 000, Loss: 0.7225, Train Acc: 0.9786, Val Acc: 0.7840, Test Acc: 0.8120\n",
            "Epoch 010, Loss: 0.7239, Train Acc: 0.9714, Val Acc: 0.7800, Test Acc: 0.8110\n",
            "Epoch 020, Loss: 0.7175, Train Acc: 0.9786, Val Acc: 0.7840, Test Acc: 0.8090\n",
            "Epoch 030, Loss: 0.7248, Train Acc: 0.9786, Val Acc: 0.7800, Test Acc: 0.8080\n",
            "Epoch 040, Loss: 0.7262, Train Acc: 0.9786, Val Acc: 0.7820, Test Acc: 0.8100\n",
            "Epoch 050, Loss: 0.7210, Train Acc: 0.9786, Val Acc: 0.7820, Test Acc: 0.8120\n",
            "Epoch 060, Loss: 0.7233, Train Acc: 0.9786, Val Acc: 0.7840, Test Acc: 0.8120\n",
            "Epoch 070, Loss: 0.7254, Train Acc: 0.9714, Val Acc: 0.7860, Test Acc: 0.8140\n",
            "Epoch 080, Loss: 0.7227, Train Acc: 0.9857, Val Acc: 0.7840, Test Acc: 0.8110\n",
            "Epoch 090, Loss: 0.7350, Train Acc: 0.9786, Val Acc: 0.7820, Test Acc: 0.8160\n",
            "Epoch 100, Loss: 0.7212, Train Acc: 0.9714, Val Acc: 0.7840, Test Acc: 0.8120\n",
            "Epoch 110, Loss: 0.7295, Train Acc: 0.9857, Val Acc: 0.7860, Test Acc: 0.8110\n",
            "Epoch 120, Loss: 0.7311, Train Acc: 0.9857, Val Acc: 0.7780, Test Acc: 0.8130\n",
            "Epoch 130, Loss: 0.7246, Train Acc: 0.9857, Val Acc: 0.7800, Test Acc: 0.8150\n",
            "Epoch 140, Loss: 0.7186, Train Acc: 0.9857, Val Acc: 0.7820, Test Acc: 0.8130\n",
            "Epoch 150, Loss: 0.7210, Train Acc: 0.9857, Val Acc: 0.7820, Test Acc: 0.8120\n",
            "Epoch 160, Loss: 0.7325, Train Acc: 0.9786, Val Acc: 0.7840, Test Acc: 0.8100\n",
            "Epoch 170, Loss: 0.7318, Train Acc: 0.9786, Val Acc: 0.7820, Test Acc: 0.8100\n",
            "Epoch 180, Loss: 0.7194, Train Acc: 0.9857, Val Acc: 0.7780, Test Acc: 0.8150\n",
            "Epoch 190, Loss: 0.7252, Train Acc: 0.9786, Val Acc: 0.7820, Test Acc: 0.8140\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def select_high_prob_nodes(data, model, target_label, num_trigger_nodes):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        output = model(data.x, data.edge_index)\n",
        "\n",
        "    # Convert log probabilities to probabilities for the target label\n",
        "    target_probs = output[:, target_label].exp()\n",
        "\n",
        "    sorted_indices = torch.argsort(target_probs, descending=True)\n",
        "    high_conf_nodes = sorted_indices[:num_trigger_nodes]\n",
        "    return high_conf_nodes"
      ],
      "metadata": {
        "id": "Nj7prsen8wxA"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def generate_trigger_graph(data, model, num_trigger_nodes=10, target_label=0):\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        output = model(data.x, data.edge_index)\n",
        "        predictions = output.argmax(dim=1)\n",
        "\n",
        "    target_nodes = torch.where(predictions == target_label)[0][:num_trigger_nodes]\n",
        "\n",
        "    # Generate trigger nodes and connect them to the selected nodes\n",
        "    trigger_features = data.x[target_nodes].clone()\n",
        "    trigger_adj = torch.eye(num_trigger_nodes)\n",
        "\n",
        "    new_features = torch.cat([data.x, trigger_features], dim=0)\n",
        "    new_adj = torch.block_diag(data.edge_index, trigger_adj)\n",
        "\n",
        "    return new_features, new_adj"
      ],
      "metadata": {
        "id": "mNBZ--WJ_Pqi"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_with_watermark(data, trigger_graph, target_label):\n",
        "    model.train()\n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    x_combined = torch.cat([data.x, trigger_graph['features']], dim=0)\n",
        "    edge_index_combined = torch.cat([data.edge_index, trigger_graph['edges']], dim=1)\n",
        "\n",
        "    output = model(x_combined, edge_index_combined)\n",
        "    loss = F.nll_loss(output[data.train_mask], data.y[data.train_mask])\n",
        "\n",
        "    trigger_loss = F.nll_loss(output[trigger_graph['nodes']], target_label)\n",
        "    total_loss = loss + trigger_loss\n",
        "\n",
        "    # Backward pass\n",
        "    total_loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    return total_loss.item()\n",
        "\n"
      ],
      "metadata": {
        "id": "mgsluEz9DO2-"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_fidelity(data):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "\n",
        "    # Forward pass on the clean graph\n",
        "    with torch.no_grad():\n",
        "        output = model(data.x, data.edge_index)\n",
        "\n",
        "    # Compute accuracy for train, validation, and test sets\n",
        "    accuracies = {}\n",
        "    for mask_name, mask in [('Train', data.train_mask),\n",
        "                            ('Validation', data.val_mask),\n",
        "                            ('Test', data.test_mask)]:\n",
        "        correct = output[mask].argmax(dim=1).eq(data.y[mask]).sum().item()\n",
        "        total = mask.sum().item()\n",
        "        accuracies[mask_name] = correct / total\n",
        "\n",
        "    return accuracies\n",
        "\n",
        "fidelity_results = evaluate_fidelity(data)\n",
        "print(\"Fidelity Results:\")\n",
        "print(f\"Train Accuracy: {fidelity_results['Train']:.4f}\")\n",
        "print(f\"Validation Accuracy: {fidelity_results['Validation']:.4f}\")\n",
        "print(f\"Test Accuracy: {fidelity_results['Test']:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XsJN3y_WFl8P",
        "outputId": "fd10be6e-301a-4079-ef3b-cb426cdc1d24"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fidelity Results:\n",
            "Train Accuracy: 0.9857\n",
            "Validation Accuracy: 0.7820\n",
            "Test Accuracy: 0.8140\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}